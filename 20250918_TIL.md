# 🗓️ 2025년 9월 18일 TIL



## 키워드 요약

* **Spring AI** LLM 통합을 위한 스프링 프레임워크
* **ChatClient** LLM과 통신하는 핵심 컴포넌트
* **프롬프트 엔지니어링** LLM의 역할과 응답 형식을 정의
* **JSON 스키마 강제** AI 응답을 정형화된 JSON으로 받기 위한 기법

---

## 개념 정리

### Spring AI
- 복잡한 LLM(거대 언어 모델) API 호출을 단순화하는 프레임워크
- 익숙한 스프링 방식으로 AI 기능을 구현할 수 있도록 도움
- OpenAI, Gemini 등 다양한 모델을 일관된 코드로 사용 가능

### ChatClient

- `ChatClient`는 LLM과 상호작용하는 핵심 컴포넌트
- `prompt()` 메서드를 통해 요청을 구성하고 `call()`로 LLM을 호출
- `WebClient`나 `RestTemplate`처럼 유창한(fluent) API 형태로 제공된다.

### 프롬프트 엔지니어링

- LLM에게 보내는 메시지
- LLM의 역할을 정의하는 **시스템 메시지**와 실제 질문/코드를 담는 **사용자 메시지**로 구성
- `AIService` 코드의 `buildSystemPrompt` 메서드가 시스템 메시지를
- `StringBuilder`로 구성한 내용이 사용자 메시지 역할을 한다.

### JSON 스키마 강제

- LLM은 종종 마크다운이나 불필요한 문장을 섞어 응답함
- 하지만 프로그램은 정형화된 JSON 데이터가 필요
- `AIService`는 시스템 프롬프트에 구체적인 JSON 스키마를 명시
- LLM이 오직 그 형식에 맞는 JSON만 출력하도록 유도
- 이는 AI 서비스의 안정성과 신뢰성을 높이는 중요한 기술이다.

---

## 코드 분석

* **`buildSystemPrompt()`**: 언어에 따라 동적으로 프롬프트 가이드를 추가한다. JSON 스키마를 강제하는 가장 중요한 부분이다.
* **`buildPreAnalysis()`**: 코드에 `eval()`, SQL 문자열 결합 등 잠재적 위험 요소를 사전 분석한다. LLM에게 더 정확한 리뷰를 위한 힌트를 제공한다.
* **`reviewCode()`**: `ChatClient`를 사용해 시스템 메시지와 사용자 메시지를 결합, LLM에 요청을 보낸다.
* **`parseReviewJson()`**: LLM 응답에서 JSON 블록만 추출하고 파싱한다. 파싱 실패를 대비한 예외 처리(try-catch)와 원본 텍스트를 반환하는 **폴백(Fallback)** 로직이 포함되어 있다.

---

## 최종 정리

* Spring AI를 사용하면 기존 백엔드 개발 흐름 그대로 AI 서비스를 구축할 수 있다.
* `ChatClient`는 LLM 연동의 진입 장벽을 낮추고, 다양한 모델을 일관된 방식으로 호출하게 해준다.
* 견고한 AI 서비스 개발을 위해 **프롬프트 엔지니어링**과 **안정적인 응답 파싱**은 필수적이다.

