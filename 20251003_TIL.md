# ğŸ—“ï¸ 2025ë…„ 10ì›” 3ì¼ TIL

## ğŸ“Š Today's Summary
- 5ê°œ ìˆ˜ì–´ ë‹¨ì–´ì— ëŒ€í•´ ê° 4ê°œì”© ì¶”ê°€ ì˜ìƒ ì´¬ì˜ (ì´ 20ê°œ)
- ë¡œì»¬ ì˜ìƒ ì¢Œí‘œ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ë° ë°ì´í„° ì¶”ê°€
- LSTM ëª¨ë¸ í•™ìŠµ: 25ê°œ ì›ë³¸ â†’ 1025ê°œ ì¦ê°• â†’ 69.76% ì •í™•ë„
- **ê²°ë¡ **: ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ 70% ë²½ ëŒíŒŒ ì–´ë ¤ì›€. ê° ë‹¨ì–´ë‹¹ ìµœì†Œ 15-20ê°œ ë‹¤ì–‘í•œ ì˜ìƒ í•„ìš”

---

## ê°„ë‹¨í•œ LSTM ëª¨ë¸ í•™ìŠµ
> LSTM ëª¨ë¸ ì½”ë“œ URL `https://github.com/Kanggwanju/python-project202508/blob/hand/LSTM_model/simple_sign_language_model_no_flip.py`

## ì˜ìƒ ì´¬ì˜
- ì§ì ‘ ìˆ˜í•™, ì¼ìš”ì¼, ë¯¸êµ­, ë¬´í•œ, ì›”ì„¸ì— ëŒ€í•œ ì˜ìƒ 4ê°œë¥¼ ì´¬ì˜

## ì¢Œí‘œ ì¶”ì¶œ
- ì½”ë“œ: `https://github.com/Kanggwanju/python-project202508/blob/hand/extractor/local_video_extractor.py`
- ì´¬ì˜í•œ ì˜ìƒì„ ì´ìš©í•˜ì—¬ npy íŒŒì¼ ìƒì„±, csv íŒŒì¼ ìˆ˜ì •
- ì„ì˜ë¡œ idë¥¼ 501ë²ˆë¶€í„° ì§€ì •í•˜ì—¬ ì¢Œí‘œë¥¼ ìˆ˜ì •í•¨
- ì¢Œí‘œ ì¶”ì¶œ ëª…ë ¹ì–´: `python .\extractor\local_video_extractor.py --video ".\data\monthlyRent\*.mp4" --label "ì›”ì„¸" --id 517 --auto-increment`

---

### ìˆ˜ì •ëœ csv íŒŒì¼ (`https://github.com/Kanggwanju/python-project202508/tree/hand/coordinates_output`)
```text
id,label,shape,total_frames,original_fps,actual_fps,frame_skip,extracted_frames
192,ìˆ˜í•™,"(149, 57, 2)",298,59.94005994005994,29.970029970029973,2,149
240,ì¼ìš”ì¼,"(99, 57, 2)",197,59.94005994005994,30.122162101857533,2,99
321,ë¯¸êµ­,"(116, 57, 2)",231,59.94005994005994,30.09977035951061,2,116
358,ë¬´í•œ,"(121, 57, 2)",241,59.94005994005994,30.09438694085997,2,121
360,ì›”ì„¸,"(111, 57, 2)",222,59.94005994005994,29.97002997002997,2,111
501,ìˆ˜í•™,"(56, 57, 2)",111,30.008110300081103,15.139226818058937,2,56
502,ìˆ˜í•™,"(56, 57, 2)",111,30.008110300081103,15.139226818058937,2,56
503,ìˆ˜í•™,"(49, 57, 2)",97,29.993815708101423,15.151515151515152,2,49
504,ìˆ˜í•™,"(39, 57, 2)",78,30.011542901115813,15.005771450557903,2,39
505,ì¼ìš”ì¼,"(56, 57, 2)",111,30.008110300081103,15.139226818058937,2,56
506,ì¼ìš”ì¼,"(53, 57, 2)",106,29.994340690435767,14.997170345217882,2,53
507,ì¼ìš”ì¼,"(48, 57, 2)",96,30.00937793060332,15.004688965301655,2,48
508,ì¼ìš”ì¼,"(51, 57, 2)",102,30.00882612533098,15.00441306266549,2,51
509,ë¯¸êµ­,"(67, 57, 2)",133,29.99548940009021,15.110509697789803,2,67
510,ë¯¸êµ­,"(66, 57, 2)",132,30.00681973175722,15.00340986587861,2,66
511,ë¯¸êµ­,"(62, 57, 2)",123,30.00731885825812,15.125640400097584,2,62
512,ë¯¸êµ­,"(77, 57, 2)",153,30.00588350656992,15.101000196116884,2,77
513,ë¬´í•œ,"(62, 57, 2)",123,30.00731885825812,15.125640400097584,2,62
514,ë¬´í•œ,"(70, 57, 2)",140,30.00428632661809,15.002143163309048,2,70
515,ë¬´í•œ,"(77, 57, 2)",153,30.00588350656992,15.101000196116884,2,77
516,ë¬´í•œ,"(67, 57, 2)",133,29.99548940009021,15.110509697789803,2,67
517,ì›”ì„¸,"(71, 57, 2)",141,30.006384337093,15.10959778676314,2,71
518,ì›”ì„¸,"(67, 57, 2)",134,30.00447828034035,15.002239140170174,2,67
519,ì›”ì„¸,"(69, 57, 2)",137,30.00438020148927,15.111695137976348,2,69
520,ì›”ì„¸,"(73, 57, 2)",146,30.004110152075626,15.002055076037811,2,73
```

---

## í•™ìŠµ ëª…ë ¹ì–´ & ë¡œê·¸
```text
î‚¶ python-project202508 î‚° python .\LSTM_model\simple_sign_language_model_no_flip.py                                                                                                            
2025-10-03 22:02:25.578524: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ì´ 25ê°œì˜ ì›ë³¸ ì‹œí€€ìŠ¤ ë¡œë“œë¨. í´ë˜ìŠ¤ ìˆ˜: 5
í´ë˜ìŠ¤ ë§¤í•‘: {'ìˆ˜í•™': 0, 'ì¼ìš”ì¼': 1, 'ë¯¸êµ­': 2, 'ë¬´í•œ': 3, 'ì›”ì„¸': 4}
ì¦ê°• í›„ ì´ 1025ê°œì˜ ì‹œí€€ìŠ¤ ìƒì„±ë¨.
íŒ¨ë”© í›„ ì‹œí€€ìŠ¤ shape: (1025, 204, 114)
ë¼ë²¨ shape: (1025, 5)
í›ˆë ¨ ë°ì´í„° shape: (820, 204, 114), ë¼ë²¨ shape: (820, 5)
í…ŒìŠ¤íŠ¸ ë°ì´í„° shape: (205, 204, 114), ë¼ë²¨ shape: (205, 5)
2025-10-03 22:02:30.268111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.    
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
C:\Users\user\AppData\Local\Programs\Python\Python310\lib\site-packages\keras\src\layers\rnn\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ lstm (LSTM)                          â”‚ (None, 204, 64)             â”‚          45,824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 204, 64)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lstm_1 (LSTM)                        â”‚ (None, 32)                  â”‚          12,416 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)                  â”‚ (None, 32)                  â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 5)                   â”‚             165 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 58,405 (228.14 KB)
 Trainable params: 58,405 (228.14 KB)
 Non-trainable params: 0 (0.00 B)

ëª¨ë¸ í•™ìŠµ ì‹œì‘...
Epoch 1/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 93ms/step - accuracy: 0.1753 - loss: 1.6111 - val_accuracy: 0.2195 - val_loss: 1.6089
Epoch 2/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.1860 - loss: 1.6093 - val_accuracy: 0.1646 - val_loss: 1.6083
Epoch 3/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.2287 - loss: 1.6064 - val_accuracy: 0.2195 - val_loss: 1.5826
Epoch 4/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.2180 - loss: 1.5957 - val_accuracy: 0.2744 - val_loss: 1.5649
Epoch 5/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.2424 - loss: 1.5783 - val_accuracy: 0.2805 - val_loss: 1.5144
Epoch 6/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.2470 - loss: 1.5569 - val_accuracy: 0.3659 - val_loss: 1.4781
Epoch 7/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.2637 - loss: 1.5620 - val_accuracy: 0.3293 - val_loss: 1.4862
Epoch 8/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.3399 - loss: 1.4828 - val_accuracy: 0.4756 - val_loss: 1.2935
Epoch 9/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.3811 - loss: 1.3940 - val_accuracy: 0.4268 - val_loss: 1.1856
Epoch 10/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.4421 - loss: 1.1905 - val_accuracy: 0.4268 - val_loss: 1.0792
Epoch 11/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.4345 - loss: 1.1091 - val_accuracy: 0.4329 - val_loss: 0.9989
Epoch 12/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.4024 - loss: 1.1056 - val_accuracy: 0.4390 - val_loss: 0.9928
Epoch 13/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 77ms/step - accuracy: 0.4497 - loss: 1.0682 - val_accuracy: 0.5244 - val_loss: 0.9091
Epoch 14/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.4162 - loss: 1.2462 - val_accuracy: 0.3049 - val_loss: 1.7017
Epoch 15/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.3277 - loss: 1.5733 - val_accuracy: 0.3902 - val_loss: 1.4694
Epoch 16/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.4299 - loss: 1.3317 - val_accuracy: 0.4268 - val_loss: 1.1385
Epoch 17/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.4284 - loss: 1.0805 - val_accuracy: 0.5183 - val_loss: 0.9533
Epoch 18/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.5412 - loss: 0.9474 - val_accuracy: 0.5915 - val_loss: 0.8008
Epoch 19/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.5534 - loss: 1.0645 - val_accuracy: 0.4573 - val_loss: 1.3320
Epoch 20/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 77ms/step - accuracy: 0.4588 - loss: 1.1992 - val_accuracy: 0.4146 - val_loss: 1.1624
Epoch 21/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 81ms/step - accuracy: 0.5076 - loss: 0.9947 - val_accuracy: 0.5122 - val_loss: 0.9362
Epoch 22/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.5747 - loss: 0.8387 - val_accuracy: 0.6037 - val_loss: 0.7751
Epoch 23/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6052 - loss: 0.7435 - val_accuracy: 0.6280 - val_loss: 0.7014
Epoch 24/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.5991 - loss: 0.7283 - val_accuracy: 0.6280 - val_loss: 0.6555
Epoch 25/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 81ms/step - accuracy: 0.5595 - loss: 0.8040 - val_accuracy: 0.5549 - val_loss: 0.8185
Epoch 26/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 77ms/step - accuracy: 0.4573 - loss: 1.3570 - val_accuracy: 0.5183 - val_loss: 0.9949
Epoch 27/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.5625 - loss: 0.8590 - val_accuracy: 0.6220 - val_loss: 0.7437
Epoch 28/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6021 - loss: 0.7250 - val_accuracy: 0.6402 - val_loss: 0.6891
Epoch 29/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6082 - loss: 0.6887 - val_accuracy: 0.6463 - val_loss: 0.6738
Epoch 30/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6479 - loss: 0.6844 - val_accuracy: 0.6159 - val_loss: 0.7322
Epoch 31/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6494 - loss: 0.6818 - val_accuracy: 0.6280 - val_loss: 0.6609
Epoch 32/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 81ms/step - accuracy: 0.6174 - loss: 0.7212 - val_accuracy: 0.6341 - val_loss: 0.6525
Epoch 33/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6311 - loss: 0.6775 - val_accuracy: 0.6341 - val_loss: 0.6548
Epoch 34/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6540 - loss: 0.6484 - val_accuracy: 0.6524 - val_loss: 0.6511
Epoch 35/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6585 - loss: 0.6280 - val_accuracy: 0.6585 - val_loss: 0.6296
Epoch 36/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6662 - loss: 0.6244 - val_accuracy: 0.6585 - val_loss: 0.6307
Epoch 37/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6860 - loss: 0.6114 - val_accuracy: 0.6585 - val_loss: 0.6233
Epoch 38/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6631 - loss: 0.6317 - val_accuracy: 0.6341 - val_loss: 0.6998
Epoch 39/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 81ms/step - accuracy: 0.6616 - loss: 0.6499 - val_accuracy: 0.6280 - val_loss: 0.6386
Epoch 40/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6585 - loss: 0.6318 - val_accuracy: 0.6524 - val_loss: 0.6023
Epoch 41/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6662 - loss: 0.6211 - val_accuracy: 0.6463 - val_loss: 0.6227
Epoch 42/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6845 - loss: 0.6269 - val_accuracy: 0.6585 - val_loss: 0.6236
Epoch 43/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6341 - loss: 0.6735 - val_accuracy: 0.6341 - val_loss: 0.6338
Epoch 44/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6265 - loss: 0.6991 - val_accuracy: 0.5732 - val_loss: 0.7400
Epoch 45/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 81ms/step - accuracy: 0.5899 - loss: 0.6928 - val_accuracy: 0.6037 - val_loss: 0.6446
Epoch 46/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.5930 - loss: 0.6719 - val_accuracy: 0.6463 - val_loss: 0.6202
Epoch 47/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6494 - loss: 0.6382 - val_accuracy: 0.6463 - val_loss: 0.6361
Epoch 48/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6631 - loss: 0.6018 - val_accuracy: 0.6524 - val_loss: 0.6034
Epoch 49/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6585 - loss: 0.6094 - val_accuracy: 0.6585 - val_loss: 0.5762
Epoch 50/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6662 - loss: 0.5899 - val_accuracy: 0.6585 - val_loss: 0.5746
Epoch 51/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6829 - loss: 0.5807 - val_accuracy: 0.6585 - val_loss: 0.5739
Epoch 52/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6601 - loss: 0.5839 - val_accuracy: 0.6585 - val_loss: 0.5677
Epoch 53/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6677 - loss: 0.5862 - val_accuracy: 0.6585 - val_loss: 0.5681
Epoch 54/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6677 - loss: 0.5889 - val_accuracy: 0.6585 - val_loss: 0.5660
Epoch 55/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6784 - loss: 0.5794 - val_accuracy: 0.6585 - val_loss: 0.5629
Epoch 56/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6753 - loss: 0.5839 - val_accuracy: 0.6585 - val_loss: 0.5654
Epoch 57/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6753 - loss: 0.5881 - val_accuracy: 0.6341 - val_loss: 0.5861
Epoch 58/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6890 - loss: 0.5925 - val_accuracy: 0.6463 - val_loss: 0.5728
Epoch 59/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6707 - loss: 0.5844 - val_accuracy: 0.6463 - val_loss: 0.5685
Epoch 60/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6494 - loss: 0.5911 - val_accuracy: 0.6585 - val_loss: 0.5650
Epoch 61/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6540 - loss: 0.5811 - val_accuracy: 0.6585 - val_loss: 0.5655
Epoch 62/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6997 - loss: 0.5764 - val_accuracy: 0.6585 - val_loss: 0.5648
Epoch 63/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6936 - loss: 0.5747 - val_accuracy: 0.6585 - val_loss: 0.5646
Epoch 64/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6677 - loss: 0.5828 - val_accuracy: 0.6707 - val_loss: 0.5641
Epoch 65/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 81ms/step - accuracy: 0.7043 - loss: 0.5646 - val_accuracy: 0.6768 - val_loss: 0.5571
Epoch 66/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6738 - loss: 0.6037 - val_accuracy: 0.6402 - val_loss: 0.6544
Epoch 67/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6494 - loss: 0.6097 - val_accuracy: 0.6341 - val_loss: 0.5702
Epoch 68/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 78ms/step - accuracy: 0.6662 - loss: 0.5947 - val_accuracy: 0.6463 - val_loss: 0.5715
Epoch 69/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6692 - loss: 0.5955 - val_accuracy: 0.6524 - val_loss: 0.5967
Epoch 70/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6585 - loss: 0.5851 - val_accuracy: 0.6159 - val_loss: 0.7898
Epoch 71/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 83ms/step - accuracy: 0.6707 - loss: 0.5880 - val_accuracy: 0.6585 - val_loss: 0.5661
Epoch 72/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6829 - loss: 0.5778 - val_accuracy: 0.6646 - val_loss: 0.5637
Epoch 73/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6921 - loss: 0.5755 - val_accuracy: 0.6585 - val_loss: 0.5677
Epoch 74/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6905 - loss: 0.5765 - val_accuracy: 0.6585 - val_loss: 0.5759
Epoch 75/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6814 - loss: 0.5952 - val_accuracy: 0.6524 - val_loss: 0.6785
Epoch 76/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.7165 - loss: 0.5728 - val_accuracy: 0.6829 - val_loss: 0.5599
Epoch 77/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.7088 - loss: 0.5569 - val_accuracy: 0.6646 - val_loss: 0.6350
Epoch 78/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6738 - loss: 0.6247 - val_accuracy: 0.5793 - val_loss: 0.9499
Epoch 79/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6555 - loss: 0.6541 - val_accuracy: 0.6280 - val_loss: 0.6692
Epoch 80/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6738 - loss: 0.6247 - val_accuracy: 0.5793 - val_loss: 0.9499
Epoch 79/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6555 - loss: 0.6541 - val_accuracy: 0.6280 - val_loss: 0.6692
Epoch 80/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6799 - loss: 0.5958 - val_accuracy: 0.6280 - val_loss: 0.6918
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6738 - loss: 0.6247 - val_accuracy: 0.5793 - val_loss: 0.9499
Epoch 79/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6555 - loss: 0.6541 - val_accuracy: 0.6280 - val_loss: 0.6692
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6738 - loss: 0.6247 - val_accuracy: 0.5793 - val_loss: 0.9499
Epoch 79/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6738 - loss: 0.6247 - val_accuracy: 0.5793 - val_loss: 0.9499
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 80ms/step - accuracy: 0.6738 - loss: 0.6247 - val_accuracy: 0.5793 - val_loss: 0.9499
Epoch 79/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6555 - loss: 0.6541 - val_accuracy: 0.6280 - val_loss: 0.6692
Epoch 80/200
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 79ms/step - accuracy: 0.6799 - loss: 0.5958 - val_accuracy: 0.6280 - val_loss: 0.6918

ëª¨ë¸ í‰ê°€ ì‹œì‘...
í…ŒìŠ¤íŠ¸ ì†ì‹¤: 0.5491
í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.6976

ì˜ˆì¸¡ ì˜ˆì‹œ:
1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 181ms/step
ì‹¤ì œ ë¼ë²¨: ë¯¸êµ­
ì˜ˆì¸¡ ë¼ë²¨: ë¯¸êµ­
ì˜ˆì¸¡ í™•ë¥ : [4.9356907e-04 1.8455979e-04 9.8956901e-01 9.5121451e-03 2.4076115e-04]
```

---

## ì˜ˆì¸¡ í™•ë¥  ë¶„ì„

```python
ì˜ˆì¸¡ í™•ë¥ : [4.9356907e-04 1.8455979e-04 9.8956901e-01 9.5121451e-03 2.4076115e-04]
```

ì´ê±´ **ê³¼í•™ì  í‘œê¸°ë²•(scientific notation)**ìœ¼ë¡œ í‘œì‹œëœ ê±°ì˜ˆìš”:

**ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ë©´:**
- `4.9356907e-04` = 0.000494 (0.049%)
- `1.8455979e-04` = 0.000185 (0.019%)
- `9.8956901e-01` = **0.989569 (98.96%)** â† ë¯¸êµ­
- `9.5121451e-03` = 0.009512 (0.95%)
- `2.4076115e-04` = 0.000241 (0.024%)

**í•´ì„:**
- ëª¨ë¸ì´ 3ë²ˆì§¸ í´ë˜ìŠ¤(ë¯¸êµ­)ì„ **98.96% í™•ë¥ **ë¡œ ì˜ˆì¸¡
- ë‚˜ë¨¸ì§€ í´ë˜ìŠ¤ë“¤ì€ ëª¨ë‘ 1% ë¯¸ë§Œ
- ì‹¤ì œ ë¼ë²¨ë„ "ë¯¸êµ­"ì´ë¯€ë¡œ **ì •í™•í•˜ê²Œ ë§ì¶¤**

## ì™œ ì´ë ‡ê²Œ í‘œì‹œë ê¹Œ?

í™•ë¥ ì´ 0.001 ì´í•˜ì²˜ëŸ¼ ë§¤ìš° ì‘ì„ ë•Œ Python/NumPyëŠ” ìë™ìœ¼ë¡œ ê³¼í•™ì  í‘œê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:
- `e-04` = 10^-4 = 0.0001
- `e-01` = 10^-1 = 0.1

ì´ê±´ ë§¤ìš° ì¢‹ì€ ì‹ í˜¸ì…ë‹ˆë‹¤. ëª¨ë¸ì´ í™•ì‹ ì„ ê°€ì§€ê³ (98.96%) ì •ë‹µì„ ë§ì¶”ê³  ìˆë‹¤ëŠ” ëœ»ì´ê±°ë“ ìš”!

---

## í´ë¡œë“œì˜ í˜„ì¬ ìƒí™© ë¶„ì„

**ê¸ì •ì ì¸ ë¶€ë¶„:**
- ëª¨ë¸ì´ í•™ìŠµì€ ë˜ê³  ìˆìŒ (ì´ˆë°˜ 17% â†’ ìµœì¢… 69.76% ì •í™•ë„)
- ê³¼ì í•©ì€ ì‹¬í•˜ì§€ ì•ŠìŒ (train/val ì •í™•ë„ ì°¨ì´ê°€ í¬ì§€ ì•ŠìŒ)
- ë°ì´í„° ì¦ê°•ì´ ì‘ë™í•˜ê³  ìˆìŒ (25ê°œ â†’ 1025ê°œ)

**ë¬¸ì œì :**
1. **ì •í™•ë„ê°€ 70% ê·¼ì²˜ì—ì„œ ì •ì²´ë¨**
    - Epoch 35 ì´í›„ë¡œ ê±°ì˜ ê°œì„ ì´ ì—†ìŒ (65.85% ê·¼ì²˜ì—ì„œ ë°˜ë³µ)
    - 5ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ 70%ëŠ” ë‚®ì€ í¸

2. **ë°ì´í„°ê°€ ì—¬ì „íˆ ë¶€ì¡±í•¨**
    - 5ê°œ ë‹¨ì–´ Ã— 5ê°œ ì˜ìƒ = 25ê°œ ì›ë³¸ ë°ì´í„°
    - ì¦ê°•ìœ¼ë¡œ 1025ê°œ ë§Œë“¤ì—ˆì§€ë§Œ, ì›ë³¸ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±
    - ê°™ì€ ì‚¬ëŒì´ ì°ì€ ê°™ì€ íŒ¨í„´ë§Œ í•™ìŠµ

3. **í•™ìŠµì´ ë¶ˆì•ˆì •í•¨**
    - val_lossê°€ íŠ€ëŠ” êµ¬ê°„ë“¤ (Epoch 14, 19, 44, 70, 78 ë“±)
    - ëª¨ë¸ì´ ì¼ë°˜í™”ë¥¼ ì–´ë ¤ì›Œí•˜ëŠ” ì‹ í˜¸

## ì¶”ì²œ ê°œì„  ë°©ì•ˆ

**1. ë” ë§ì€ ì‹¤ì œ ì˜ìƒ í•„ìš”**
```
ê° ë‹¨ì–´ë‹¹ ìµœì†Œ 10-20ê°œ ì˜ìƒ ê¶Œì¥
- ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì°ì€ ì˜ìƒ
- ë‹¤ë¥¸ ê°ë„, ë‹¤ë¥¸ ì†ë„ë¡œ ì°ì€ ì˜ìƒ
- ì¡°ëª…ì´ ë‹¤ë¥¸ í™˜ê²½
```

**2. ì¦ê°• íšŸìˆ˜ ì¡°ì •**
í˜„ì¬ `num_augmentations=40`ì€ ê³¼ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì›ë³¸ì´ 5ê°œë°–ì— ì—†ëŠ”ë° ê°ê°ì„ 40ë²ˆì”© ì¦ê°•í•˜ë©´ ê±°ì˜ ê°™ì€ ë°ì´í„°ë¥¼ ë°˜ë³µ í•™ìŠµí•˜ëŠ” ê²ƒê³¼ ë¹„ìŠ·í•©ë‹ˆë‹¤.

**3. ëª¨ë¸ ë³µì¡ë„ ì¤„ì´ê¸°**
ë°ì´í„°ê°€ ì ì„ ë•ŒëŠ” ë” ë‹¨ìˆœí•œ ëª¨ë¸ì´ ë‚˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í˜„ì‹¤ì ì¸ íŒë‹¨:**
5ê°œ ë‹¨ì–´ì— ê° 5ê°œ ì˜ìƒìœ¼ë¡œ 70% ì •í™•ë„ë©´ ë‚˜ì˜ì§€ ì•Šì€ ì¶œë°œì ì´ì§€ë§Œ,
ì‹¤ìš©ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸°ì—” ë¶€ì¡±í•©ë‹ˆë‹¤.
ê° ë‹¨ì–´ë‹¹ ìµœì†Œ 15-20ê°œì˜ **ì„œë¡œ ë‹¤ë¥¸** ì˜ìƒì„ í™•ë³´í•˜ëŠ” ê²Œ ìš°ì„ ì…ë‹ˆë‹¤.


